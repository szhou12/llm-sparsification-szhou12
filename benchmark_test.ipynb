{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import datasets\n",
    "from datasets import load_metric\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds.predictions, eval_preds.label_ids\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "def save2Json(metrics, filename):\n",
    "    json_object = json.dumps(metrics, indent=4)\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "\n",
    "\n",
    "def run_benchmark_single(model_name, tokenizer_checkpoint, model_checkpoint, SPARSE_PERCENT):\n",
    "    raw_datasets = datasets.load_dataset('glue', 'mrpc')\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)\n",
    "    def tokenize_function(sample):\n",
    "        return tokenizer(sample['sentence1'], sample['sentence2'], truncation=True)\n",
    "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        num_train_epochs = 1,\n",
    "        output_dir=f'output/glue-{model_name}_{SPARSE_PERCENT}/',\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        data_collator=data_collator, \n",
    "        tokenizer=tokenizer,\n",
    "        # compute_metrics=compute_metrics\n",
    "    )\n",
    "    print(f\"Start training {model_checkpoint}...\")\n",
    "\n",
    "    trains = trainer.train()\n",
    "    # predictions = trainer.predict(tokenized_datasets['validation'])\n",
    "    save2Json(trains.metrics, filename=f'output/glue-{model_name}_{SPARSE_PERCENT}.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/Users/shuyuzhou/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72aa5286b0ed4f5ba8ec14837460ce80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4955a02c976b47598b5da3f70b40cbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e549a8d567484d228a8ab91232e03c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bcc7604ab04e0cba0a23cc71d2bd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3668\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 459\n",
      "  Number of trainable parameters = 124441344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ./models/gpt2-glue_0.1/...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff64a0d88b2b4c41abb3bdd88728307c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1958.2886, 'train_samples_per_second': 1.873, 'train_steps_per_second': 0.234, 'train_loss': 0.6446202762246391, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_benchmark_single(\n",
    "    model_name=\"gpt2\", \n",
    "    tokenizer_checkpoint='./models/gpt2-glue-tokenizer/', \n",
    "    model_checkpoint=\"./models/gpt2-glue_0.1/\", \n",
    "    SPARSE_PERCENT=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
